{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "boston = pd.read_csv('../BostonHousing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem1 i)\n",
    "dataset = pd.read_csv('../BostonHousing.csv')\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dataset['medv']\n",
    "X=dataset.drop(['medv'],axis=1,inplace=False)\n",
    "X=X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation(x, y):\n",
    "    # Compute means\n",
    "    x_mean = np.mean(x, axis=0)\n",
    "    y_mean = np.mean(y, axis=0)\n",
    "\n",
    "    # Compute standard deviations\n",
    "    x_std = np.std(x, axis=0)\n",
    "    y_std = np.std(y, axis=0)\n",
    "\n",
    "    # Compute covariance\n",
    "    covariance = np.mean((x - x_mean) * (y - y_mean), axis=0)\n",
    "\n",
    "    # Return Pearson correlation coefficient\n",
    "    return covariance / (x_std * y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Pearson correlation coefficients\n",
    "#print(X[:,0])\n",
    "result =[]\n",
    "for i in range(0,12):\n",
    "    calc_pearson = pearson_correlation(X[:,i], y)\n",
    "    result.append(calc_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38830460858681165, 0.36044534245054316, -0.48372516002837285, 0.1752601771902984, -0.4273207723732827, 0.6953599470715394, -0.3769545650045962, 0.2499287340859039, -0.3816262306397781, -0.468535933567767, -0.507786685537562, 0.33346081965706653]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal component analysis (PCA) is a statistical method that is used to reduce the dimensionality of a dataset.\n",
    "It does this by finding new, lower-dimensional representations of the data that capture the most important variations in the data.\n",
    "\n",
    "The algorithm works by first calculating the covariance matrix of the data,\n",
    "which describes the correlations between the different features in the data. \n",
    "The covariance matrix is then decomposed using singular value decomposition (SVD) or eigendecomposition to find the eigenvectors and eigenvalues of the matrix.\n",
    "\n",
    "The eigenvectors of the covariance matrix are the principal components of the data, \n",
    "and the eigenvalues describe the amount of variation in the data that is captured by each principal component. \n",
    "The PCA algorithm then selects the top k eigenvectors (where k is the number of dimensions we want to reduce the data to), and projects the data onto the new subspace defined by these k eigenvectors.\n",
    "\n",
    "The result is a new, lower-dimensional dataset that captures the most important variations in the original data. \n",
    "This can be useful for a number of applications, such as data visualization, noise reduction, and feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii)\n",
    "import numpy as np\n",
    "\n",
    "def pca(X, num_components):\n",
    "  # Mean center the data\n",
    "  X_mean = X - np.mean(X, axis=0)\n",
    "\n",
    "  # Calculate the covariance matrix\n",
    "  cov = np.cov(X_mean, rowvar=False)\n",
    "\n",
    "  # Calculate the eigenvalues and eigenvectors of the covariance matrix\n",
    "  eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "\n",
    "  # Sort the eigenvalues and eigenvectors in descending order\n",
    "  idx = eigenvalues.argsort()[::-1]\n",
    "  eigenvalues = eigenvalues[idx]\n",
    "  eigenvectors = eigenvectors[:,idx]\n",
    "\n",
    "  # Take the top `num_components` eigenvectors\n",
    "  W = eigenvectors[:, :num_components]\n",
    "\n",
    "  # Project the data onto the new subspace\n",
    "  X_pca = np.dot(X_mean, W)\n",
    "\n",
    "  return X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.19817596e+02, -5.53898918e+00, -3.26792041e+00, ...,\n",
       "         5.42164681e-02,  2.79565938e-02,  1.78979032e-02],\n",
       "       [-1.68809338e+02,  1.01744592e+01, -3.10760869e+01, ...,\n",
       "        -6.27963975e-02,  7.52030847e-02, -3.98505128e-02],\n",
       "       [-1.69565571e+02,  1.40216969e+01, -1.61322371e+01, ...,\n",
       "        -2.43410351e-01,  1.30514856e-01,  5.49956408e-03],\n",
       "       ...,\n",
       "       [-1.38375366e+02,  9.68067975e-01, -3.73212636e+01, ...,\n",
       "        -4.39683382e-01,  6.98734040e-02,  3.23952370e-02],\n",
       "       [-1.37445002e+02,  4.29816287e+00, -3.61671961e+01, ...,\n",
       "        -3.64928299e-01,  5.87735280e-02,  3.33854893e-02],\n",
       "       [-1.38872152e+02,  1.14494212e+00, -3.07284370e+01, ...,\n",
       "        -8.21368020e-02, -3.78083159e-03,  1.88600393e-02]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_data = dataset.to_numpy()\n",
    "pca_12com = pca(dataset,len(pca_data))\n",
    "pca_12com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-119.81759621,   -5.53898918,   -3.26792041],\n",
       "       [-168.8093378 ,   10.17445922,  -31.07608687],\n",
       "       [-169.56557101,   14.02169685,  -16.13223709],\n",
       "       ...,\n",
       "       [-138.37536643,    0.96806797,  -37.3212636 ],\n",
       "       [-137.44500197,    4.29816287,  -36.16719605],\n",
       "       [-138.87215156,    1.14494212,  -30.72843699]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pca(dataset,3)\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-119.81759621,   -5.53898918,   -3.26792041],\n",
       "       [-168.8093378 ,   10.17445922,  -31.07608687],\n",
       "       [-169.56557101,   14.02169685,  -16.13223709],\n",
       "       ...,\n",
       "       [-138.37536643,    0.96806797,  -37.3212636 ],\n",
       "       [-137.44500197,    4.29816287,  -36.16719605],\n",
       "       [-138.87215156,    1.14494212,  -30.72843699]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#compare with sklearn dataset \n",
    "pca = PCA(n_components = 3)\n",
    "pca_transformed = pca.fit_transform(dataset)\n",
    "pca_transformed\n",
    "\n",
    "dataset['pca_x'] = pca_transformed[:, 0]  #x coordinate\n",
    "dataset['pca_y'] = pca_transformed[:, 1]  #y coordinate\n",
    "dataset['pca_z'] = pca_transformed[:, 2]  #z coordinate\n",
    "\n",
    "pca_transformed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为上次作业没有写 k_fold,这次补交,逻辑如下<br>\n",
    "1. shuffle the data to ensure that the samples are distributed randomly<br>\n",
    "2. split the data into K \"folds\" or partitions of the data<br>\n",
    "3. iterate over the folds and use each one as a validation set, while the other folds are used as the training set<br>\n",
    "4. train my model using the training sets and evaluate it using the validation set<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logic\n",
    "def k_fold(data, k, model):\n",
    "    # Split the data into k folds\n",
    "    folds = np.array_split(data, k)\n",
    "\n",
    "    # Train and evaluate the model k times\n",
    "    scores = []\n",
    "    for i in range(k):\n",
    "        # Create the training and validation sets\n",
    "        train_index = np.concatenate(folds[:i] + folds[i+1:])\n",
    "        val_index = folds[i]\n",
    "        X_train, X_test = X[train_index], X[val_index]\n",
    "        y_train, y_test = y[train_index], y[val_index]\n",
    "        # Train the model on the training folds\n",
    "        model.fit(train_index)\n",
    "\n",
    "        # Evaluate the model on the validation fold\n",
    "        score = model.evaluate(val_index)\n",
    "        scores.append(score)\n",
    "\n",
    "    # Average the performance metrics\n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08511fb726953861695b9cebc649e5cfa50177e02ef8da1c1316f73897c02d54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
